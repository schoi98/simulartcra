{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulartcra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List\n",
    "import collections\n",
    "import inspect\n",
    "import tenacity\n",
    "from termcolor import colored\n",
    "import os\n",
    "import io\n",
    "import warnings\n",
    "from PIL import Image\n",
    "from stability_sdk import client\n",
    "import stability_sdk.interfaces.gooseai.generation.generation_pb2 as generation\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import Tool, initialize_agent\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import (\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "from langchain.output_parsers import RegexParser\n",
    "from langchain_experimental.generative_agents import (\n",
    "    GenerativeAgent,\n",
    "    GenerativeAgentMemory,\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['STABILITY_HOST'] = 'grpc.stability.ai:443'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_NAME = \"schoi\"  # The name you want to use when interviewing the agent.\n",
    "LLM = ChatOpenAI(max_tokens=1500, model=\"gpt-3.5-turbo-0613\")  # Can be any LLM you want.\n",
    "\n",
    "# Set up our connection to the API.\n",
    "stability_api = client.StabilityInference(\n",
    "    key=os.environ['STABILITY_KEY'], # API Key reference.\n",
    "    verbose=True, # Print debug messages.\n",
    "    engine=\"stable-diffusion-xl-1024-v1-0\", # Set the engine to use for generation.\n",
    "    # Check out the following link for a list of available engines: https://platform.stability.ai/docs/features/api-parameters#engine\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import faiss\n",
    "\n",
    "\n",
    "def relevance_score_fn(score: float) -> float:\n",
    "    \"\"\"Return a similarity score on a scale [0, 1].\"\"\"\n",
    "    # This will differ depending on a few things:\n",
    "    # - the distance / similarity metric used by the VectorStore\n",
    "    # - the scale of your embeddings (OpenAI's are unit norm. Many others are not!)\n",
    "    # This function converts the euclidean norm of normalized embeddings\n",
    "    # (0 is most similar, sqrt(2) most dissimilar)\n",
    "    # to a similarity function (0 to 1)\n",
    "    return 1.0 - score / math.sqrt(2)\n",
    "\n",
    "\n",
    "def create_new_memory_retriever():\n",
    "    \"\"\"Create a new vector store retriever unique to the agent.\"\"\"\n",
    "    # Define your embedding model\n",
    "    embeddings_model = OpenAIEmbeddings()\n",
    "    # Initialize the vectorstore as empty\n",
    "    embedding_size = 1536\n",
    "    index = faiss.IndexFlatL2(embedding_size)\n",
    "    vectorstore = FAISS(\n",
    "        embeddings_model.embed_query,\n",
    "        index,\n",
    "        InMemoryDocstore({}),\n",
    "        {},\n",
    "        relevance_score_fn=relevance_score_fn,\n",
    "    )\n",
    "    return TimeWeightedVectorStoreRetriever(\n",
    "        vectorstore=vectorstore, other_score_keys=[\"importance\"], k=15\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stability ai art\n",
    "def generate_art(prompt, turn, seed=4253978046, init_img=None, mask=None, samples=1, steps=50, cfg_scale=8.0, width=1024, height=1024, sampler=generation.SAMPLER_K_DPMPP_2M):\n",
    "    answers = stability_api.generate(\n",
    "        prompt=prompt,\n",
    "        init_image=init_img, # Assign our previously generated img as our Initial Image for transformation.\n",
    "        mask_image=mask,\n",
    "        seed=seed, # If a seed is provided, the resulting generated image will be deterministic.\n",
    "                        # What this means is that as long as all generation parameters remain the same, you can always recall the same image simply by generating it again.\n",
    "                        # Note: This isn't quite the case for Clip Guided generations, which we'll tackle in a future example notebook.\n",
    "        steps=steps, # Amount of inference steps performed on image generation. Defaults to 30. \n",
    "        cfg_scale=cfg_scale, # Influences how strongly your generation is guided to match your prompt.\n",
    "        width=width, # Generation width, defaults to 512 if not included.\n",
    "        height=height, # Generation height, defaults to 512 if not included.\n",
    "        samples=samples, # Number of images to generate, defaults to 1 if not included.\n",
    "        sampler=sampler\n",
    "    )\n",
    "    for resp in answers:\n",
    "        for artifact in resp.artifacts:\n",
    "            if artifact.finish_reason == generation.FILTER:\n",
    "                warnings.warn(\n",
    "                    \"Your request activated the API's safety filters and could not be processed.\"\n",
    "                    \"Please modify the prompt and try again.\")\n",
    "            if artifact.type == generation.ARTIFACT_IMAGE:\n",
    "                img = Image.open(io.BytesIO(artifact.binary))\n",
    "                img.save(f\"result_{turn:02d}.png\") # Save our generated images with their seed number as the filename.\n",
    "\n",
    "def iterate_art(prompt, init_img, turn, seed=4253978046, mask=None, samples=1, steps=50, cfg_scale=8.0, width=1024, height=1024, sampler=generation.SAMPLER_K_DPMPP_2M):\n",
    "    answers = stability_api.generate(\n",
    "        prompt=prompt,\n",
    "        init_image=init_img, # Assign our previously generated img as our Initial Image for transformation.\n",
    "        mask_image=mask,\n",
    "        seed=seed, # If a seed is provided, the resulting generated image will be deterministic.\n",
    "                        # What this means is that as long as all generation parameters remain the same, you can always recall the same image simply by generating it again.\n",
    "                        # Note: This isn't quite the case for Clip Guided generations, which we'll tackle in a future example notebook.\n",
    "        steps=steps, # Amount of inference steps performed on image generation. Defaults to 30. \n",
    "        cfg_scale=cfg_scale, # Influences how strongly your generation is guided to match your prompt.\n",
    "        width=width, # Generation width, defaults to 512 if not included.\n",
    "        height=height, # Generation height, defaults to 512 if not included.\n",
    "        samples=samples, # Number of images to generate, defaults to 1 if not included.\n",
    "        sampler=sampler\n",
    "    )\n",
    "    for resp in answers:\n",
    "        for artifact in resp.artifacts:\n",
    "            if artifact.finish_reason == generation.FILTER:\n",
    "                warnings.warn(\n",
    "                    \"Your request activated the API's safety filters and could not be processed.\"\n",
    "                    \"Please modify the prompt and try again.\")\n",
    "            if artifact.type == generation.ARTIFACT_IMAGE:\n",
    "                img = Image.open(io.BytesIO(artifact.binary))\n",
    "                img.save(f\"result_{turn:02d}.png\") # Save our generated images with their seed number as the filename."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerativeAgentWithFunctions(GenerativeAgent):\n",
    "    \"\"\"\n",
    "    Allow for function calling \n",
    "    \"\"\"\n",
    "    def __init__(self, agent, functions):\n",
    "        self.agent = agent\n",
    "        self.functions = functions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"generate art\",\n",
    "        func=generate_art,\n",
    "        description=\"Generate a new art piece with an idea\",\n",
    "    ), \n",
    "    Tool(\n",
    "        name=\"iterate art\",\n",
    "        func=iterate_art,\n",
    "        description=\"Iterate on an existing art piece with additional details\",\n",
    "    )\n",
    "]\n",
    "\n",
    "alices_memory = GenerativeAgentMemory(\n",
    "    llm=LLM,\n",
    "    memory_retriever=create_new_memory_retriever(),\n",
    "    verbose=False,\n",
    "    reflection_threshold=8,  # we will give this a relatively low number to show how reflection works\n",
    ")\n",
    "\n",
    "alice = GenerativeAgentWithFunctions(\n",
    "    agent=GenerativeAgent(\n",
    "        name=\"Alice\",\n",
    "        age=25,\n",
    "        traits=\"likes classical art, action driven\",  # You can add more persistent traits here\n",
    "        status=\"wants to create art\",  # When connected to a virtual world, we can have the characters update their status\n",
    "        memory_retriever=create_new_memory_retriever(),\n",
    "        llm=LLM,\n",
    "        memory=alices_memory,\n",
    "    ), \n",
    "    functions=tools\n",
    ")\n",
    "\n",
    "bobs_memory = GenerativeAgentMemory(\n",
    "    llm=LLM,\n",
    "    memory_retriever=create_new_memory_retriever(),\n",
    "    verbose=False,\n",
    "    reflection_threshold=8,  # we will give this a relatively low number to show how reflection works\n",
    ")\n",
    "\n",
    "bob = GenerativeAgentWithFunctions(\n",
    "    agent=GenerativeAgent(\n",
    "        name=\"Bob\",\n",
    "        age=25,\n",
    "        traits=\"likes modern art, action driven\",  # You can add more persistent traits here\n",
    "        status=\"wants to create art\",  # When connected to a virtual world, we can have the characters update their status\n",
    "        memory_retriever=create_new_memory_retriever(),\n",
    "        llm=LLM,\n",
    "        memory=bobs_memory,\n",
    "    ), \n",
    "    functions=tools\n",
    ")\n",
    "\n",
    "# We can add memories directly to the memory object\n",
    "\n",
    "observations = [\n",
    "    \" is going to collaborating on creating art\",\n",
    "    \" can create new art by saying GENERATE\",\n",
    "    \" can iterate on the existing art by saying ITERATE\",\n",
    "]\n",
    "for observation in observations:\n",
    "    alice.gen.memory.add_memory(\"Alice\" + observation)\n",
    "    bob.memory.add_memory(\"Bob\" + observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interview_agent(agent: GenerativeAgent, message: str) -> str:\n",
    "    \"\"\"Help the notebook user interact with the agent.\"\"\"\n",
    "    new_message = f\"{USER_NAME} says {message}\"\n",
    "    return agent.generate_dialogue_response(new_message)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interview_agent(alice, \"What do you like to do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interview_agent(bob, \"What do you like to do?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Event Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(agents: List[GenerativeAgent], initial_observation: str, max_turns=10) -> None:\n",
    "    \"\"\"\n",
    "    Simulate Art Creation\n",
    "    TODO: Create a canvas environment for gymnasium or something similar\n",
    "    I am no good at prompt engineering for actions. it worked once\n",
    "    \"\"\"\n",
    "    _, observation = agents[1].generate_reaction(initial_observation)\n",
    "    print(observation)\n",
    "    turns = 0\n",
    "    prev_generated = turns\n",
    "    generated = False\n",
    "    while True:\n",
    "        if turns > max_turns:\n",
    "            break\n",
    "        break_dialogue = False\n",
    "        for agent in agents:\n",
    "            stay_in_dialogue, observation = agent.generate_dialogue_response(\n",
    "                observation\n",
    "            )\n",
    "            print(observation)\n",
    "            # observation = f\"{agent.name} said {reaction}\"\n",
    "            generate = observation.find(\"GENERATE\")\n",
    "            iterate = observation.find(\"ITERATE\")\n",
    "            if generate >= 0 and not generated:\n",
    "                generate_art(observation, turns)\n",
    "                prev_generated = turns\n",
    "                generated = True\n",
    "                for agent in agents:\n",
    "                    agent.memory.add_memory(\"An initial art piece was generated, I should now only say ITERATE with an improvement\")\n",
    "            if iterate >= 0:\n",
    "                generate_art(observation, turns, init_img=f\"result_{prev_generated:02d}.png\")\n",
    "                prev_generated = turns\n",
    "            if not stay_in_dialogue:\n",
    "                break_dialogue = True\n",
    "        if break_dialogue:\n",
    "            break\n",
    "        turns += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents=[alice, bob]\n",
    "initial_observation = \"\"\"\n",
    "Alice said: Hello Bob! Are you ready to create the art piece for the demo? The theme is 'imagination' lets generate the art as soon as possible and iterate.\n",
    "\"\"\"\n",
    "main(agents, initial_observation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ishb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
